{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f2e602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T22:41:59.173677Z",
     "iopub.status.busy": "2024-06-30T22:41:59.173338Z",
     "iopub.status.idle": "2024-06-30T22:42:16.862749Z",
     "shell.execute_reply": "2024-06-30T22:42:16.861956Z"
    },
    "papermill": {
     "duration": 17.698649,
     "end_time": "2024-06-30T22:42:16.864942",
     "exception": false,
     "start_time": "2024-06-30T22:41:59.166293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 22:42:06.543875: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-30 22:42:06.544001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-30 22:42:06.680118: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg19\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import vgg19\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac2b6a",
   "metadata": {
    "papermill": {
     "duration": 0.005957,
     "end_time": "2024-06-30T22:42:16.877323",
     "exception": false,
     "start_time": "2024-06-30T22:42:16.871366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Move Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed9eeadf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T22:42:16.891019Z",
     "iopub.status.busy": "2024-06-30T22:42:16.890459Z",
     "iopub.status.idle": "2024-06-30T22:42:16.895154Z",
     "shell.execute_reply": "2024-06-30T22:42:16.894388Z"
    },
    "papermill": {
     "duration": 0.013582,
     "end_time": "2024-06-30T22:42:16.897035",
     "exception": false,
     "start_time": "2024-06-30T22:42:16.883453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Source directory\n",
    "# source_dir = '/kaggle/input/flickr2k/Flickr2K/Flickr2K_HR/'\n",
    "\n",
    "# # Destination directory\n",
    "# destination_dir = '/kaggle/working/dataset'\n",
    "\n",
    "# # Ensure destination directory exists\n",
    "# os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# # Get list of files in source directory\n",
    "# files = os.listdir(source_dir)\n",
    "\n",
    "# # Copy each file from source to destination\n",
    "# for file in files:\n",
    "#     source_file = os.path.join(source_dir, file)\n",
    "#     destination_file = os.path.join(destination_dir, file)\n",
    "#     shutil.copy(source_file, destination_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf55f8",
   "metadata": {
    "papermill": {
     "duration": 0.006783,
     "end_time": "2024-06-30T22:42:16.910443",
     "exception": false,
     "start_time": "2024-06-30T22:42:16.903660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae9d8e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T22:42:16.924370Z",
     "iopub.status.busy": "2024-06-30T22:42:16.923679Z",
     "iopub.status.idle": "2024-06-30T22:42:16.981934Z",
     "shell.execute_reply": "2024-06-30T22:42:16.981186Z"
    },
    "papermill": {
     "duration": 0.067001,
     "end_time": "2024-06-30T22:42:16.983841",
     "exception": false,
     "start_time": "2024-06-30T22:42:16.916840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOAD_MODEL = True\n",
    "SAVE_MODEL = True\n",
    "CHECKPOINT_GEN = \"/kaggle/working/gen.pth\"\n",
    "CHECKPOINT_DISC = \"/kaggle/working/disc.pth\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 2e-4\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "LAMBDA_GP = 10\n",
    "NUM_WORKERS = 8\n",
    "HIGH_RES = 128\n",
    "LOW_RES = HIGH_RES // 4\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "highres_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "lowres_transform = A.Compose(\n",
    "    [\n",
    "      \n",
    "        A.Resize(width=LOW_RES, height=LOW_RES,interpolation=Image.BICUBIC),\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "both_transforms = A.Compose(\n",
    "    [\n",
    "    A.Resize(width=HIGH_RES, height=HIGH_RES,interpolation=Image.LANCZOS),\n",
    "\n",
    "#         A.RandomCrop(width=HIGH_RES, height=HIGH_RES),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec641eb",
   "metadata": {
    "papermill": {
     "duration": 0.006084,
     "end_time": "2024-06-30T22:42:16.996227",
     "exception": false,
     "start_time": "2024-06-30T22:42:16.990143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce08990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T22:42:17.009812Z",
     "iopub.status.busy": "2024-06-30T22:42:17.009524Z",
     "iopub.status.idle": "2024-06-30T22:42:17.021025Z",
     "shell.execute_reply": "2024-06-30T22:42:17.020186Z"
    },
    "papermill": {
     "duration": 0.0205,
     "end_time": "2024-06-30T22:42:17.022849",
     "exception": false,
     "start_time": "2024-06-30T22:42:17.002349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_srgan(loader, generator, device='cuda', num_images=1, log_dir='/kaggle/working/logs'):\n",
    "    \"\"\"\n",
    "    Plots low-resolution, generated, and high-resolution images from the SRGAN model.\n",
    "\n",
    "    Parameters:\n",
    "    loader (DataLoader): DataLoader for the dataset.\n",
    "    generator (torch.nn.Module): Generator model.\n",
    "    device (str): Device to run the model on ('cuda' or 'cpu').\n",
    "    num_images (int): Number of images to display.\n",
    "    log_dir (str): Directory to save log files (default: './logs').\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    # Get a batch of data\n",
    "    data_iter = iter(loader)\n",
    "    lr_images, hr_images = next(data_iter)\n",
    "\n",
    "    # Select a few images to plot\n",
    "    lr_images = lr_images[:num_images]\n",
    "    hr_images = hr_images[:num_images]\n",
    "\n",
    "    # Move images to the device\n",
    "    lr_images = lr_images.to(device)\n",
    "    hr_images = hr_images.to(device)\n",
    "\n",
    "    # Generate super-resolution images\n",
    "    with torch.no_grad():\n",
    "        sr_images = generator(lr_images)\n",
    "\n",
    "    # Move images back to CPU for plotting\n",
    "    lr_images = lr_images.cpu()\n",
    "    sr_images = sr_images.cpu()\n",
    "    hr_images = hr_images.cpu()\n",
    "\n",
    "#     lr_images = (lr_images+1)/2.0*255.0\n",
    "#     sr_images = (sr_images+1)/2.0*255.0\n",
    "#     hr_images = (hr_images+1)/2.0*255.0\n",
    "    \n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Plot and save images\n",
    "    for i in range(num_images):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        # Plot Low Resolution image\n",
    "        axes[0].imshow(lr_images[i].permute(1, 2, 0))\n",
    "        axes[0].set_title('Low Resolution')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # Plot Super Resolution image\n",
    "        axes[1].imshow(sr_images[i].permute(1, 2, 0))\n",
    "        axes[1].set_title('Super Resolution')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        # Plot High Resolution image\n",
    "        axes[2].imshow(hr_images[i].permute(1, 2, 0))\n",
    "        axes[2].set_title('High Resolution')\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        # Save figure\n",
    "        fig_path = os.path.join(log_dir, f'image_{i+1}.png')\n",
    "        plt.savefig(fig_path)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Log the figure path in Kaggle's output\n",
    "        print(f'![image_{i+1}](./{fig_path})')\n",
    "\n",
    "    generator.train()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a4384",
   "metadata": {
    "papermill": {
     "duration": 0.005971,
     "end_time": "2024-06-30T22:42:17.034963",
     "exception": false,
     "start_time": "2024-06-30T22:42:17.028992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d7cf00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T22:42:17.049278Z",
     "iopub.status.busy": "2024-06-30T22:42:17.049018Z",
     "iopub.status.idle": "2024-06-30T22:42:17.061879Z",
     "shell.execute_reply": "2024-06-30T22:42:17.061065Z"
    },
    "papermill": {
     "duration": 0.021772,
     "end_time": "2024-06-30T22:42:17.063754",
     "exception": false,
     "start_time": "2024-06-30T22:42:17.041982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MyImageFolder(Dataset):\n",
    "    def __init__(self, root_dirs):\n",
    "        super(MyImageFolder, self).__init__()\n",
    "        self.root_dirs = root_dirs\n",
    "        self.image_files = self.collect_image_files()\n",
    "\n",
    "    def collect_image_files(self):\n",
    "        image_files = []\n",
    "        for root_dir in self.root_dirs:\n",
    "            image_files.extend([os.path.join(root_dir, f) for f in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, f))])\n",
    "        return image_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_files[index]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "\n",
    "        image = both_transforms(image=image)[\"image\"]  # Assuming both_transforms is defined elsewhere\n",
    "        high_res = highres_transform(image=image)[\"image\"]  # Assuming highres_transform is defined elsewhere\n",
    "        low_res = lowres_transform(image=image)[\"image\"]  # Assuming lowres_transform is defined elsewhere\n",
    "\n",
    "        return low_res, high_res\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    return torch.stack([item[0] for item in batch]), torch.stack([item[1] for item in batch])\n",
    "\n",
    "def plot_(low_res, high_res):\n",
    "    num_images = len(low_res)\n",
    "    fig, axes = plt.subplots(num_images, 2, figsize=(10, 10))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        lr_img = np.transpose(low_res[i].numpy(), (1, 2, 0))  # Assuming low_res is a Tensor\n",
    "        hr_img = np.transpose(high_res[i].numpy(), (1, 2, 0))  # Assuming high_res is a Tensor\n",
    "        \n",
    "        axes[i, 0].imshow(lr_img)\n",
    "        axes[i, 0].set_title('Low Resolution')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(hr_img)\n",
    "        axes[i, 1].set_title('High Resolution')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedd1da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T22:42:17.077183Z",
     "iopub.status.busy": "2024-06-30T22:42:17.076927Z",
     "iopub.status.idle": "2024-06-30T22:42:20.371213Z",
     "shell.execute_reply": "2024-06-30T22:42:20.370248Z"
    },
    "papermill": {
     "duration": 3.30397,
     "end_time": "2024-06-30T22:42:20.373865",
     "exception": false,
     "start_time": "2024-06-30T22:42:17.069895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dirs = [ '/kaggle/input/flickr2k/Flickr2K/Flickr2K_HR'\n",
    "                 \n",
    "            \n",
    "                ]\n",
    "dataset = MyImageFolder(root_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0c269",
   "metadata": {
    "papermill": {
     "duration": 0.007198,
     "end_time": "2024-06-30T22:42:20.388558",
     "exception": false,
     "start_time": "2024-06-30T22:42:20.381360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d5543ec",
   "metadata": {
    "papermill": {
     "duration": 0.006916,
     "end_time": "2024-06-30T22:42:20.402696",
     "exception": false,
     "start_time": "2024-06-30T22:42:20.395780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7baca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T22:42:20.418588Z",
     "iopub.status.busy": "2024-06-30T22:42:20.418267Z",
     "iopub.status.idle": "2024-06-30T22:42:20.449640Z",
     "shell.execute_reply": "2024-06-30T22:42:20.448871Z"
    },
    "papermill": {
     "duration": 0.041792,
     "end_time": "2024-06-30T22:42:20.451757",
     "exception": false,
     "start_time": "2024-06-30T22:42:20.409965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, nf=64, gc=32):\n",
    "        super(ResidualDenseBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(nf, gc, 3, padding=1, bias=True)\n",
    "        self.conv2 = nn.Conv2d(nf + gc, gc, 3, padding=1, bias=True)\n",
    "        self.conv3 = nn.Conv2d(nf + 2 * gc, gc, 3, padding=1, bias=True)\n",
    "        self.conv4 = nn.Conv2d(nf + 3 * gc, gc, 3, padding=1, bias=True)\n",
    "        self.conv5 = nn.Conv2d(nf + 4 * gc, nf, 3, padding=1, bias=True)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.lrelu(self.conv1(x))\n",
    "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
    "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
    "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
    "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
    "        return x5 * 0.2 + x\n",
    "\n",
    "class RRDB(nn.Module):\n",
    "    def __init__(self, nf):\n",
    "        super(RRDB, self).__init__()\n",
    "        self.rdb1 = ResidualDenseBlock(nf)\n",
    "        self.rdb2 = ResidualDenseBlock(nf)\n",
    "        self.rdb3 = ResidualDenseBlock(nf)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.rdb1(x)\n",
    "        out = self.rdb2(out)\n",
    "        out = self.rdb3(out)\n",
    "        return out * 0.2 + x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_rrdb_blocks=23):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv_first = nn.Conv2d(3, 64, 3, padding=1, bias=True)\n",
    "        self.body = nn.Sequential(*[RRDB(64) for _ in range(num_rrdb_blocks)])\n",
    "        self.conv_body = nn.Conv2d(64, 64, 3, padding=1, bias=True)\n",
    "        self.conv_up1 = nn.Conv2d(64, 64, 3, padding=1, bias=True)\n",
    "        self.conv_up2 = nn.Conv2d(64, 64, 3, padding=1, bias=True)\n",
    "        self.conv_hr = nn.Conv2d(64, 64, 3, padding=1, bias=True)\n",
    "        self.conv_last = nn.Conv2d(64, 3, 3, padding=1, bias=True)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.conv_first(x)\n",
    "        body_feat = self.conv_body(self.body(feat))\n",
    "        feat = feat + body_feat\n",
    "        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
    "        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
    "        feat = self.conv_last(self.lrelu(self.conv_hr(feat)))\n",
    "        return feat\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(512, 1024, kernel_size=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(1024, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        output = self.classifier(features)\n",
    "        return output.view(output.size(0), -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b063109",
   "metadata": {
    "papermill": {
     "duration": 0.006767,
     "end_time": "2024-06-30T22:42:20.465439",
     "exception": false,
     "start_time": "2024-06-30T22:42:20.458672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a59b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T22:42:20.480625Z",
     "iopub.status.busy": "2024-06-30T22:42:20.480341Z",
     "iopub.status.idle": "2024-06-30T22:42:20.486197Z",
     "shell.execute_reply": "2024-06-30T22:42:20.485205Z"
    },
    "papermill": {
     "duration": 0.016,
     "end_time": "2024-06-30T22:42:20.488382",
     "exception": false,
     "start_time": "2024-06-30T22:42:20.472382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        vgg19_model = vgg19(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(vgg19_model.features.children())[:35])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc63bc70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T22:42:20.503563Z",
     "iopub.status.busy": "2024-06-30T22:42:20.503265Z",
     "iopub.status.idle": "2024-06-30T22:42:20.524891Z",
     "shell.execute_reply": "2024-06-30T22:42:20.523924Z"
    },
    "papermill": {
     "duration": 0.031588,
     "end_time": "2024-06-30T22:42:20.526939",
     "exception": false,
     "start_time": "2024-06-30T22:42:20.495351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class ESRGAN:\n",
    "    def __init__(self, lr=1e-5, num_epochs=5, batch_size=8):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.generator = Generator().to(self.device)\n",
    "        self.discriminator = Discriminator().to(self.device)\n",
    "        self.feature_extractor = FeatureExtractor().to(self.device)\n",
    "        \n",
    "        self.generator_optimizer = optim.Adam(self.generator.parameters(), lr=lr)\n",
    "        self.discriminator_optimizer = optim.Adam(self.discriminator.parameters(), lr=lr)\n",
    "        \n",
    "        self.content_criterion = nn.L1Loss()\n",
    "        self.adversarial_criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train(self, train_dataloader):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            tqdm_dataloader = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{self.num_epochs}\", leave=False)\n",
    "            for i, (lr_imgs, hr_imgs) in enumerate(tqdm_dataloader):\n",
    "                lr_imgs = lr_imgs.to(self.device)\n",
    "                hr_imgs = hr_imgs.to(self.device)\n",
    "                \n",
    "                # Train Discriminator\n",
    "                self.discriminator_optimizer.zero_grad()\n",
    "                \n",
    "                sr_imgs = self.generator(lr_imgs)\n",
    "                real_preds = self.discriminator(hr_imgs)\n",
    "                fake_preds = self.discriminator(sr_imgs.detach())\n",
    "                \n",
    "                d_loss_real = self.adversarial_criterion(real_preds - fake_preds.mean(), torch.ones_like(real_preds))\n",
    "                d_loss_fake = self.adversarial_criterion(fake_preds - real_preds.mean(), torch.zeros_like(fake_preds))\n",
    "                d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "                \n",
    "                d_loss.backward()\n",
    "                self.discriminator_optimizer.step()\n",
    "                \n",
    "                # Train Generator\n",
    "                self.generator_optimizer.zero_grad()\n",
    "                \n",
    "                sr_imgs = self.generator(lr_imgs)\n",
    "                fake_preds = self.discriminator(sr_imgs)\n",
    "                real_preds = self.discriminator(hr_imgs)\n",
    "                \n",
    "                content_loss = self.content_criterion(sr_imgs, hr_imgs)\n",
    "                adversarial_loss = self.adversarial_criterion(fake_preds - real_preds.mean(), torch.ones_like(fake_preds))\n",
    "                perceptual_loss = self.content_criterion(self.feature_extractor(sr_imgs), self.feature_extractor(hr_imgs))\n",
    "                \n",
    "                g_loss = content_loss + 0.001 * adversarial_loss + 0.006 * perceptual_loss\n",
    "                \n",
    "                g_loss.backward()\n",
    "                self.generator_optimizer.step()\n",
    "                \n",
    "                # Print or log detailed loss information for D and G\n",
    "                if i % 100 == 0 or i==166:\n",
    "                    d_loss_item = d_loss.item()\n",
    "                    g_loss_item = g_loss.item()\n",
    "                    print(f\"Epoch [{epoch+1}/{self.num_epochs}], Step [{i+1}/{len(train_dataloader)}], \"\n",
    "                          f\"D_loss: {d_loss_item:.4f}, G_loss: {g_loss_item:.4f}, \"\n",
    "                          f\"Content_loss: {content_loss.item():.4f}, \"\n",
    "                          f\"Adversarial_loss: {adversarial_loss.item():.4f}, \"\n",
    "                          f\"Perceptual_loss: {perceptual_loss.item():.4f}\")\n",
    "                    plot_srgan(train_dataloader,self.generator, self.device)\n",
    "            \n",
    "            tqdm_dataloader.close()\n",
    "            \n",
    "            # Save models after each epoch if needed\n",
    "            if SAVE_MODEL:\n",
    "                self.save_models(\"/kaggle/working\")\n",
    "\n",
    "    def save_models(self, path):\n",
    "        torch.save(self.generator.state_dict(), f\"{path}/generator.pth\")\n",
    "        torch.save(self.discriminator.state_dict(), f\"{path}/discriminator.pth\")\n",
    "\n",
    "    def load_models(self, path):\n",
    "        generator_path = os.path.join(path, \"generator.pth\")\n",
    "        discriminator_path = os.path.join(path, \"discriminator.pth\")\n",
    "\n",
    "        if os.path.exists(generator_path):\n",
    "            self.generator.load_state_dict(torch.load(generator_path))\n",
    "            print(f\"Generator model loaded successfully from {generator_path}.\")\n",
    "        else:\n",
    "            print(f\"Generator model file not found at {generator_path}. Skipping generator loading.\")\n",
    "\n",
    "        if os.path.exists(discriminator_path):\n",
    "            self.discriminator.load_state_dict(torch.load(discriminator_path))\n",
    "            print(f\"Discriminator model loaded successfully from {discriminator_path}.\")\n",
    "        else:\n",
    "            print(f\"Discriminator model file not found at {discriminator_path}. Skipping discriminator loading.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbda4452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T22:42:20.542024Z",
     "iopub.status.busy": "2024-06-30T22:42:20.541679Z",
     "iopub.status.idle": "2024-06-30T22:42:20.547661Z",
     "shell.execute_reply": "2024-06-30T22:42:20.546771Z"
    },
    "papermill": {
     "duration": 0.015917,
     "end_time": "2024-06-30T22:42:20.549905",
     "exception": false,
     "start_time": "2024-06-30T22:42:20.533988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    root_dirs = [ '/kaggle/input/flickr2k/Flickr2K/Flickr2K_HR',\n",
    "                 '/kaggle/input/flickrfaceshq-dataset-ffhq'\n",
    "            \n",
    "                ]\n",
    "    dataset = MyImageFolder(root_dirs)\n",
    "    print(f\"total numbers of images to train {dataset.__len__()}\")\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        collate_fn=custom_collate_fn,\n",
    "    )\n",
    "    esrgan = ESRGAN()\n",
    "    esrgan.train(loader)\n",
    "    if SAVE_MODEL:\n",
    "        esrgan.save_models(\"/kaggle/working\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 546691,
     "sourceId": 997012,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2813430,
     "sourceId": 4853613,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9321.710849,
   "end_time": "2024-07-01T01:17:17.357895",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-30T22:41:55.647046",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
